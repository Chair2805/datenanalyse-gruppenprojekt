# 1.1.Data Leakage and biases 
### Tasks: 
*1.1.1- In the summary above, you’ll notice that they perform a regression of their engineered
features against UPDRS score. They then predict UPDRS score to define a measure called
NQI. They then use NQI as a feature to classify Parkinson’s vs Healthy. Something seems
fishy here. Discuss this for no more than a paragraph (hint: this might be a form of data
leakage).
1.1.2- Think carefully about the tapping dataset. Can you imagine any biases that might
creep into our dataset? For example, if a patient has Parkinson’s disease, they might use a
computer less (because the disease prevents them), and as such the differences in typing
might be a training effect rather than a disease effect. Discuss this for no more than two
paragraphs (you can use bullet points).*

General definition: Data leakage is defined as the process of feeding data to an algorithm during training that would not be available at prediction time. This results in the model outperforming its intended performance (i.e. cheating). (https://www.ibm.com/think/topics/data-leakage-machine-learning).

### 1.1.1.
In this paper (Giancardo et al., 2016), the researchers created an algorithm to distinguish Parkinson’s disease (PD) patients at the early stage of the disease from comparable healthy controls. They analyzed participants’ typing behavior using a standard keyboard by recording the hold time (HT), which is the duration between pressing and releasing each key. The HT data from each participant was split into non-overlapping 90-second windows, and from each window, 7 statistical features were extracted. These features were then used in a regression model to predict the clinical UPDRS-III motor score, which is a standardized measure of PD motor symptom severity. The output of this regression — called the neuroQWERTY index (nQi) — was then used as a feature to classify participants as either having Parkinson’s or being healthy.
However, this pipeline introduces a serious data leakage issue. Because the model is trained to predict UPDRS-III, a score already strongly correlated with Parkinson’s diagnosis, the resulting nQi is inherently encoded with diagnostic information. Using it as input to a classifier effectively gives the model access to the labels it is supposed to predict. This can artificially enhance the model's performance metrics and increase the risk of overfitting, making the approach less reliable when applied to new, unseen populations where UPDRS scores are not available or might not generalize well.

### 1.1.2. 
Furthermore, there are several biases that may affect the dataset. A major confounding issue is the different lifestyles of the participants. Typing is a habitual behavior—it can be learned and improved with practice, and its speed depends on how often the skill is used. Therefore, even factors like participants’ jobs (e.g., office work) can influence the results.
A person with Parkinson’s disease might use a keyboard less frequently due to discomfort or motor difficulties compared to a healthy person, leading to reduced practice over time. As a result, their low performance in the typing task could reflect lifestyle changes or disuse, rather than a direct motor symptom of the disease.





